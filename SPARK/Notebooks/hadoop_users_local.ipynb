{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-15T12:11:46.828844",
     "start_time": "2017-01-15T12:11:44.797120"
    },
    "collapsed": false,
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "import sys,os,re\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "Spark_Path='/opt/cloudera/parcels/CDH-5.8.2-1.cdh5.8.2.p0.3/lib/spark'\n",
    "\n",
    "spark_home=Spark_Path + '/'#spark-' + SPARK_VER  +'-bin-hadoop2.6/'\n",
    "os.environ['SPARK_HOME']=spark_home\n",
    "os.environ['HADOOP_CONF_DIR']='/etc/hadoop/conf/'\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.9-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "sconf=SparkConf()\n",
    "\n",
    "master='local'\n",
    "AppName=\"Hadoop users\"\n",
    "num_executors=1\n",
    "\n",
    "sconf.set('spark.master',master)\n",
    "sconf.set('spark.executor.instances',str(num_executors))#Number of executors\n",
    "#sconf.set('spark.shuffle.service.enabled',True)\n",
    "#sconf.set('spark.dynamicAllocation.enabled',True)\n",
    "sconf.set('spark.executor.memory','1g')\n",
    "sconf.set('spark.driver.memory','1g')\n",
    "#sconf.set('spark.executor.cores','2') # number of cores on same worker\n",
    "sconf.set('spark.app.name',AppName) #Application Name\n",
    "sconf.set('spark.app.id',AppName)\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(conf=sconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import HiveContext\n",
    "sqlContext = HiveContext(sc)\n",
    "#from pyspark import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "!cat /home/kentt/shared/code/spark_in_jupyter/sparklogo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-15T12:11:46.914590",
     "start_time": "2017-01-15T12:11:46.830613"
    },
    "collapsed": false,
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/kentt/shared/data/hadoop_nasjon_messy.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f26cba81492d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/kentt/shared/data/hadoop_nasjon_messy.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mraw_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Data stored as a textfile on disk:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/kentt/shared/data/hadoop_nasjon_messy.txt'"
     ]
    }
   ],
   "source": [
    "# Read raw data\n",
    "with open('/home/kentt/shared/data/hadoop_nasjon_messy.txt', 'r') as myfile:\n",
    "    raw_data=myfile.read().splitlines()\n",
    "\n",
    "print \"Data stored as a textfile on disk:\\n\"\n",
    "print raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-20T14:41:06.578099",
     "start_time": "2016-09-20T14:41:05.657057"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Number of users with \"Hadoop\" in their profile',\n",
       " 'Norway 273,(8),Telenor,(8),DNV GL,(5),Affecto,(5),Tata Consultancy Services,(4),Microsoft']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load to Spark\n",
    "raw_data_spark=sc.parallelize(raw_data)\n",
    "raw_data_spark.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-20T14:41:07.480278",
     "start_time": "2016-09-20T14:41:07.359991"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Norway 273',\n",
       "  '(8)',\n",
       "  'Telenor',\n",
       "  '(8)',\n",
       "  'DNV GL',\n",
       "  '(5)',\n",
       "  'Affecto',\n",
       "  '(5)',\n",
       "  'Tata Consultancy Services',\n",
       "  '(4)',\n",
       "  'Microsoft'],\n",
       " ['Sweden 863',\n",
       "  '(55)',\n",
       "  'Ericsson',\n",
       "  '(44)',\n",
       "  'Spotify',\n",
       "  '(28)',\n",
       "  'Klarna',\n",
       "  '(25)',\n",
       "  'King',\n",
       "  '(18)',\n",
       "  'KTH Royal Institute of Technology']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop header\n",
    "raw_data_spark1 = raw_data_spark.filter(lambda row: row[0][0] != '#')\\\n",
    ".map(lambda row: row.split(','))\n",
    "raw_data_spark1.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-20T14:41:08.858724",
     "start_time": "2016-09-20T14:41:08.785639"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['273',\n",
       "  'Norway',\n",
       "  '(8)',\n",
       "  'Telenor',\n",
       "  '(8)',\n",
       "  'DNV GL',\n",
       "  '(5)',\n",
       "  'Affecto',\n",
       "  '(5)',\n",
       "  'Tata Consultancy Services',\n",
       "  '(4)',\n",
       "  'Microsoft'],\n",
       " ['863',\n",
       "  'Sweden',\n",
       "  '(55)',\n",
       "  'Ericsson',\n",
       "  '(44)',\n",
       "  'Spotify',\n",
       "  '(28)',\n",
       "  'Klarna',\n",
       "  '(25)',\n",
       "  'King',\n",
       "  '(18)',\n",
       "  'KTH Royal Institute of Technology']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse Norway 273 as (273), Norway \n",
    "raw_data_spark2 = raw_data_spark1\\\n",
    ".map(lambda row: [row[0].split(' ')[1],row[0].split(' ')[0]]+row[1:])\n",
    "\n",
    "raw_data_spark2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-20T14:41:10.055008",
     "start_time": "2016-09-20T14:41:09.978478"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[273,\n",
       "  'Norway',\n",
       "  8,\n",
       "  'Telenor',\n",
       "  8,\n",
       "  'DNV GL',\n",
       "  5,\n",
       "  'Affecto',\n",
       "  5,\n",
       "  'Tata Consultancy Services',\n",
       "  4,\n",
       "  'Microsoft'],\n",
       " [863,\n",
       "  'Sweden',\n",
       "  55,\n",
       "  'Ericsson',\n",
       "  44,\n",
       "  'Spotify',\n",
       "  28,\n",
       "  'Klarna',\n",
       "  25,\n",
       "  'King',\n",
       "  18,\n",
       "  'KTH Royal Institute of Technology']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unwanted chars and set dtypes\n",
    "raw_data_spark3=raw_data_spark2\\\n",
    ".map(lambda row: [i.translate(None,\"()\") for i in row])\\\n",
    ".map(lambda row: [int(i) if i.isdigit() else i for i in row])\n",
    "\n",
    "raw_data_spark3.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-20T14:41:19.236377",
     "start_time": "2016-09-20T14:41:11.324875"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------+--------------------+--------+----------------+--------+--------------------+--------+--------------------+--------+--------------------+\n",
      "|num_country|country|num_top1|        top1_company|num_top2|    top2_company|num_top3|        top3_company|num_top4|        top4_company|num_top5|        top5_company|\n",
      "+-----------+-------+--------+--------------------+--------+----------------+--------+--------------------+--------+--------------------+--------+--------------------+\n",
      "|        273| Norway|       8|             Telenor|       8|          DNV GL|       5|             Affecto|       5|Tata Consultancy ...|       4|           Microsoft|\n",
      "|        863| Sweden|      55|            Ericsson|      44|         Spotify|      28|              Klarna|      25|                King|      18|KTH Royal Institu...|\n",
      "|       6170| France|     137|           Capgemini|     131|Amadeus IT Group|     117|              Orange|      99|              Criteo|      87|        Sopra Steria|\n",
      "|        419|Denmark|      20|              Nordea|      15|     Danske Bank|       8|           Microsoft|       8|                SKAT|       7|         Maersk Line|\n",
      "|        621|Finland|      22|Tata Consultancy ...|      19|           Tieto|      12|    Aalto University|      11|           Microsoft|      11|Rovio Entertainme...|\n",
      "|       9422|     UK|     124|                 IBM|     112|       Capgemini|      94|                HSBC|      77|Tata Consultancy ...|      73|Lloyds Banking Group|\n",
      "|       3703|Germany|      77|                 SAP|      49|      Zalando SE|      40|                 IBM|      37|                HERE|      33|            Datameer|\n",
      "|       1368| Poland|      39|        EPAM Systems|      38|         Allegro|      30|Hewlett Packard E...|      29|              Luxoft|      21|                 IBM|\n",
      "+-----------+-------+--------+--------------------+--------+----------------+--------+--------------------+--------+--------------------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data is parsed. Create schema and dataframe\n",
    "schema = StructType([\\\n",
    "    StructField(\"num_country\", IntegerType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"num_top1\", IntegerType(), True),\n",
    "    StructField(\"top1_company\", StringType(), True),\n",
    "    StructField(\"num_top2\", IntegerType(), True),\n",
    "    StructField(\"top2_company\", StringType(), True),\n",
    "    StructField(\"num_top3\", IntegerType(), True),\n",
    "    StructField(\"top3_company\", StringType(), True),\n",
    "    StructField(\"num_top4\", IntegerType(), True),\n",
    "    StructField(\"top4_company\", StringType(), True),\n",
    "    StructField(\"num_top5\", IntegerType(), True),\n",
    "    StructField(\"top5_company\", StringType(), True)])\n",
    "    \n",
    "hadoop_users = sqlContext.createDataFrame(raw_data_spark3, schema)\n",
    "hadoop_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-20T14:41:23.113900",
     "start_time": "2016-09-20T14:41:22.906100"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|no_country|no_citizens|\n",
      "+----------+-----------+\n",
      "|    Sweden|      9.593|\n",
      "|    Norway|      5.084|\n",
      "|   Denmark|      5.614|\n",
      "|   Finland|      5.439|\n",
      "|        UK|       64.1|\n",
      "|   Germany|      80.62|\n",
      "|    Poland|      38.53|\n",
      "|    France|      66.03|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe with no. citizens pr. country\n",
    "no_citizens = pd.read_csv('/home/kentt/shared/data/hadoop_nasjon_no_comment.csv',sep='\\t')\n",
    "no_citizens=sqlContext.createDataFrame(no_citizens[['no_country','no_citizens']])\n",
    "no_citizens.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-20T14:41:27.004166",
     "start_time": "2016-09-20T14:41:23.970387"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------+\n",
      "|country|num_country|  num_country_norm|\n",
      "+-------+-----------+------------------+\n",
      "|     UK|       9422|146.98907956318254|\n",
      "| France|       6170| 93.44237467817659|\n",
      "|Germany|       3703|45.931530637558915|\n",
      "| Poland|       1368|35.504801453412924|\n",
      "| Sweden|        863| 89.96143020952778|\n",
      "|Finland|        621|114.17539988968561|\n",
      "|Denmark|        419| 74.63484146775917|\n",
      "| Norway|        273| 53.69787568843431|\n",
      "+-------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join if we want to\n",
    "hadoop_users_with_no_citizens = hadoop_users.join(no_citizens, hadoop_users.country == no_citizens.no_country, 'inner').drop('no_country')\n",
    "\n",
    "# Include column with normalized number of Hadoop users\n",
    "hadoop_users_with_no_citizens_with_norm = hadoop_users_with_no_citizens\\\n",
    ".withColumn(\"num_country_norm\",hadoop_users_with_no_citizens.num_country.cast(\"double\") / hadoop_users_with_no_citizens.no_citizens) \n",
    "\n",
    "\n",
    "hadoop_users_with_no_citizens_with_norm.select(\"country\",\"num_country\",\"num_country_norm\").orderBy(\"num_country\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-20T14:41:29.530525",
     "start_time": "2016-09-20T14:41:28.029952"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"134706ca-b255-486b-a7ec-6a762d7e821a\" style=\"height: 800px; width: 1000px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"134706ca-b255-486b-a7ec-6a762d7e821a\", [{\"reversescale\": true, \"autocolorscale\": false, \"colorscale\": [[0.0, \"rgb(165,0,38)\"], [0.1111111111111111, \"rgb(215,48,39)\"], [0.2222222222222222, \"rgb(244,109,67)\"], [0.3333333333333333, \"rgb(253,174,97)\"], [0.4444444444444444, \"rgb(254,224,144)\"], [0.5555555555555556, \"rgb(224,243,248)\"], [0.6666666666666666, \"rgb(171,217,233)\"], [0.7777777777777778, \"rgb(116,173,209)\"], [0.8888888888888888, \"rgb(69,117,180)\"], [1.0, \"rgb(49,54,149)\"]], \"text\": [\"Ericsson:  55<br>Spotify:  44<br>Klarna:  28<br>King:  25<br>KTH Royal Institute of Technology:  18<br>\", \"SAP:  77<br>Zalando SE:  49<br>IBM:  40<br>HERE:  37<br>Datameer:  33<br>\", \"Capgemini:  137<br>Amadeus IT Group:  131<br>Orange:  117<br>Criteo:  99<br>Sopra Steria:  87<br>\", \"Tata Consultancy Services:  22<br>Tieto:  19<br>Aalto University:  12<br>Microsoft:  11<br>Rovio Entertainment Ltd.:  11<br>\", \"Telenor:  8<br>DNV GL:  8<br>Affecto:  5<br>Tata Consultancy Services:  5<br>Microsoft:  4<br>\", \"Nordea:  20<br>Danske Bank:  15<br>Microsoft:  8<br>SKAT:  8<br>Maersk Line:  7<br>\", \"IBM:  124<br>Capgemini:  112<br>HSBC:  94<br>Tata Consultancy Services:  77<br>Lloyds Banking Group:  73<br>\", \"EPAM Systems:  39<br>Allegro:  38<br>Hewlett Packard Enterprise:  30<br>Luxoft:  29<br>IBM:  21<br>\"], \"locations\": [\"SWE\", \"DEU\", \"FRA\", \"FIN\", \"NOR\", \"DNK\", \"GBR\", \"POL\"], \"colorbar\": {\"tickprefix\": \"\", \"title\": \"No. of users\"}, \"type\": \"choropleth\", \"marker\": {\"line\": {\"color\": \"rgb(180,180,180)\", \"width\": 0.5}}, \"z\": [863, 3703, 6170, 621, 273, 419, 9422, 1368], \"locationmode\": \"Europe\"}], {\"geo\": {\"scope\": \"europe\", \"countrywidth\": \"1\", \"showcountries\": true, \"projection\": {\"type\": \"merc\"}}, \"width\": \"1000\", \"title\": \"2016 - LinkedIn users with \\\"Hadoop\\\" in profile\", \"margin\": {\"l\": \"10\"}, \"height\": \"800\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(hadoop_users_with_no_citizens_with_norm.toPandas(),'num_country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-20T14:41:46.276003",
     "start_time": "2016-09-20T14:41:45.409388"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"44213162-a5f3-4411-9452-884bb3abe67e\" style=\"height: 800px; width: 1000px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"44213162-a5f3-4411-9452-884bb3abe67e\", [{\"reversescale\": true, \"autocolorscale\": false, \"colorscale\": [[0.0, \"rgb(165,0,38)\"], [0.1111111111111111, \"rgb(215,48,39)\"], [0.2222222222222222, \"rgb(244,109,67)\"], [0.3333333333333333, \"rgb(253,174,97)\"], [0.4444444444444444, \"rgb(254,224,144)\"], [0.5555555555555556, \"rgb(224,243,248)\"], [0.6666666666666666, \"rgb(171,217,233)\"], [0.7777777777777778, \"rgb(116,173,209)\"], [0.8888888888888888, \"rgb(69,117,180)\"], [1.0, \"rgb(49,54,149)\"]], \"text\": [\"Ericsson:  55<br>Spotify:  44<br>Klarna:  28<br>King:  25<br>KTH Royal Institute of Technology:  18<br>\", \"SAP:  77<br>Zalando SE:  49<br>IBM:  40<br>HERE:  37<br>Datameer:  33<br>\", \"Capgemini:  137<br>Amadeus IT Group:  131<br>Orange:  117<br>Criteo:  99<br>Sopra Steria:  87<br>\", \"Tata Consultancy Services:  22<br>Tieto:  19<br>Aalto University:  12<br>Microsoft:  11<br>Rovio Entertainment Ltd.:  11<br>\", \"Telenor:  8<br>DNV GL:  8<br>Affecto:  5<br>Tata Consultancy Services:  5<br>Microsoft:  4<br>\", \"Nordea:  20<br>Danske Bank:  15<br>Microsoft:  8<br>SKAT:  8<br>Maersk Line:  7<br>\", \"IBM:  124<br>Capgemini:  112<br>HSBC:  94<br>Tata Consultancy Services:  77<br>Lloyds Banking Group:  73<br>\", \"EPAM Systems:  39<br>Allegro:  38<br>Hewlett Packard Enterprise:  30<br>Luxoft:  29<br>IBM:  21<br>\"], \"locations\": [\"SWE\", \"DEU\", \"FRA\", \"FIN\", \"NOR\", \"DNK\", \"GBR\", \"POL\"], \"colorbar\": {\"tickprefix\": \"\", \"title\": \"No. of users\"}, \"type\": \"choropleth\", \"marker\": {\"line\": {\"color\": \"rgb(180,180,180)\", \"width\": 0.5}}, \"z\": [89.96143020952778, 45.931530637558915, 93.44237467817659, 114.17539988968561, 53.69787568843431, 74.63484146775917, 146.98907956318254, 35.504801453412924], \"locationmode\": \"Europe\"}], {\"geo\": {\"scope\": \"europe\", \"countrywidth\": \"1\", \"showcountries\": true, \"projection\": {\"type\": \"merc\"}}, \"width\": \"1000\", \"title\": \"2016 - LinkedIn users with \\\"Hadoop\\\" in profile\", \"margin\": {\"l\": \"10\"}, \"height\": \"800\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(hadoop_users_with_no_citizens_with_norm.toPandas(),'num_country_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-15T12:11:46.915548",
     "start_time": "2017-01-15T11:11:44.802Z"
    },
    "collapsed": false,
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "def plot_results(df,plot_col='num_country'):\n",
    "    df[\"con_codes\"]=['SWE','DEU','FRA','FIN','NOR','DNK','GBR','POL']\n",
    "    data = [ dict(\n",
    "            type = 'choropleth',\n",
    "            locations = df['con_codes'],\n",
    "            z = df[plot_col],\n",
    "            text = df['top1_company']+':  '+df['num_top1'].astype(str)+'<br>'\\\n",
    "            +df['top2_company']+':  '+df['num_top2'].astype(str)+'<br>'\\\n",
    "            +df['top3_company']+':  '+df['num_top3'].astype(str)+'<br>'\\\n",
    "            +df['top4_company']+':  '+df['num_top4'].astype(str)+'<br>'\\\n",
    "            +df['top5_company']+':  '+df['num_top5'].astype(str)+'<br>',\n",
    "            colorscale=[[0.0, 'rgb(165,0,38)'], [0.1111111111111111, 'rgb(215,48,39)']\\\n",
    "                        , [0.2222222222222222, 'rgb(244,109,67)'], [0.3333333333333333, 'rgb(253,174,97)']\\\n",
    "                        , [0.4444444444444444, 'rgb(254,224,144)'], [0.5555555555555556, 'rgb(224,243,248)']\\\n",
    "                        , [0.6666666666666666, 'rgb(171,217,233)'], [0.7777777777777778, 'rgb(116,173,209)']\\\n",
    "                        , [0.8888888888888888, 'rgb(69,117,180)'], [1.0, 'rgb(49,54,149)']],\n",
    "            autocolorscale = False,\n",
    "            reversescale = True,\n",
    "            locationmode = 'Europe',\n",
    "            marker = dict(\n",
    "                line = dict (\n",
    "                    color = 'rgb(180,180,180)',\n",
    "                    width = 0.5\n",
    "                ) ),\n",
    "            colorbar = dict(\n",
    "                #autotick = False,\n",
    "                tickprefix = '',\n",
    "                title = 'No. of users'),\n",
    "          ) ]\n",
    "\n",
    "    layout = dict(\n",
    "            title = '2016 - LinkedIn users with \"Hadoop\" in profile',\n",
    "            geo = dict(\n",
    "                scope='europe',\n",
    "                projection=dict( type='merc' ),\n",
    "                countrywidth='1',\n",
    "                showcountries=True),\n",
    "            width  = '1000',\n",
    "            height = '800',\n",
    "            margin = dict(\n",
    "                l = '10',) \n",
    "            #    b = '1',)\n",
    "         )\n",
    "\n",
    "\n",
    "    fig = dict( data=data, layout=layout )\n",
    "  \n",
    "    return iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialisation Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
