{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:19:46.792885",
     "start_time": "2016-11-08T12:19:46.785085"
    },
    "collapsed": true,
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#SPARK BINDINGS\n",
    "execfile(\"/etc/spark/conf/spark_1.6.0_binings.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:19:48.594845",
     "start_time": "2016-11-08T12:19:48.171118"
    },
    "collapsed": true,
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#PYTHON IMPORTS\n",
    "import ais\n",
    "from Geohash import geohash\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import happybase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:20:03.734023",
     "start_time": "2016-11-08T12:19:51.618251"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SPARK CONF\n",
    "# Set distribution mode, appname, and claim resources\n",
    "master='yarn-client' #\"yarn\" to run distributed mode in yarn, \"local\" to run local\n",
    "#dmode='client' #spark2.0 only\n",
    "AppName=\"AIS - streaming Kystverket\"\n",
    "num_executors=2\n",
    "exec_memory=1 #in GigaByte pr. executor. Tot mem = num_executors*exec_memory\n",
    "driver_memory=1 #in GigaByte.\n",
    "\n",
    "\n",
    "\n",
    "#############--==DO NOT EDIT==--###############\n",
    "from pyspark import SparkConf\n",
    "sconf=SparkConf()\n",
    "\n",
    "sconf.set('spark.master',master)\n",
    "#sconf.set('spark.submit.deployMode',dmode) #spark2.0 only\n",
    "sconf.set('spark.executor.instances',str(num_executors))#Number of executors\n",
    "#sconf.set('spark.shuffle.service.enabled',True)\n",
    "#sconf.set('spark.dynamicAllocation.enabled',True)\n",
    "sconf.set('spark.executor.memory',str(exec_memory)+'g')\n",
    "sconf.set('spark.driver.memory',str(driver_memory)+'g')\n",
    "#sconf.set('spark.executor.cores','4') # number of cores on same worker\n",
    "sconf.set('spark.app.name',AppName) #Application Name\n",
    "sconf.set('spark.app.id',AppName)\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "sc = SparkContext(conf=sconf)\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:20:07.759173",
     "start_time": "2016-11-08T12:20:07.750664"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Spark DataFrame API's\n",
    "from pyspark import HiveContext\n",
    "sqlContext = HiveContext(sc)\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:20:27.532927",
     "start_time": "2016-11-08T12:20:15.082315"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'ssc' in locals():\n",
    "    del ssc\n",
    "\n",
    "batch_interval=1 #Seconds\n",
    "ssc = StreamingContext(sc, batch_interval)\n",
    "\n",
    "#Kystverket's open streaming connection:\n",
    "streaming_host=\"153.44.253.27\"\n",
    "streaming_port=5631\n",
    "\n",
    "spark_stream(sc, ssc,sqlContext,streaming_host,streaming_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:51:49.993050",
     "start_time": "2016-11-08T12:51:49.983466"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stop StreamingContext but keep SparkContext alive for re-use\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T13:28:32.126915",
     "start_time": "2016-11-08T13:28:32.073174"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stop SparkContext\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:20:11.943253",
     "start_time": "2016-11-08T12:20:11.658122"
    },
    "collapsed": false,
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def spark_stream(sc, ssc,sqlContext,streaming_host,streaming_port):\n",
    "    #Connect to stream\n",
    "    nmea = ssc.socketTextStream(streaming_host, streaming_port)\n",
    "\n",
    "    #Set region of interest\n",
    "    #bbox=[lllat,lllon,urlat,urlon]\n",
    "    #bbox=[59.522784,10.559235,59.924356,10.806427] <- Oslofjorden \n",
    "    bbox=[0,0,100,100]\n",
    "    \n",
    "    # Decode and filter bad messages\n",
    "    nmea_decoded = nmea.map(lambda x: try_decode(x,bbox))\n",
    "    nmea_decoded = nmea_decoded.filter(lambda x:x!=[])\n",
    "    \n",
    "    # Connect to HBase and add metadata about vessel\n",
    "    nmea_decoded = nmea_decoded.map(lambda x: x+[get_meta_from_mmsi(str(x[0]))[\"P:imo\"],\\\n",
    "                                                 get_meta_from_mmsi(str(x[0]))[\"P:name\"],\\\n",
    "                                                 get_meta_from_mmsi(str(x[0]))[\"P:type\"]])\n",
    "    \n",
    "    #since rdd is small collect and save to local FS\n",
    "    nmea_decoded.map(lambda x: rdd_list_to_str(x)).foreachRDD(lambda rdd: save_to_local(rdd.collect()))\n",
    "    \n",
    "    # Run!\n",
    "    ssc.start()\n",
    "    ssc.awaitTermination(timeout=10)\n",
    "    \n",
    "def save_to_local(rdd_collected):\n",
    "    filen='ais_'+str(int(time.time()))\n",
    "    dirpath=\"/STAGING/DATASETS/AIS/dump08112016/\"\n",
    "    with open(dirpath+filen, 'w') as file_handler:\n",
    "        for item in rdd_collected:\n",
    "            file_handler.write(item+'\\n')\n",
    "    os.system(\"chmod 777 \"+dirpath+filen)\n",
    "    \n",
    "\n",
    "def rdd_list_to_str(rdd_list): \n",
    "    rdd_str=''\n",
    "    for el in rdd_list:\n",
    "        rdd_str=rdd_str+','+str(el)\n",
    "    \n",
    "    return rdd_str[1:]\n",
    "\n",
    "def get_meta_from_mmsi(mmsi):\n",
    "    #Create connection\n",
    "    connection = happybase.Connection('2.sherpa.client.sysedata.no')\n",
    "    connection.open()\n",
    "\n",
    "    table_name=\"mmsiShipInfo\"\n",
    "    table = connection.table(table_name)\n",
    "    info_dict=table.row(mmsi)\n",
    "    if info_dict=={}:\n",
    "        info_dict={'P:imo': 'not_found','P:mmsi': mmsi,'P:name': 'not_found','P:type': 'not_found'}\n",
    "    \n",
    "    connection.close()\n",
    "    return info_dict\n",
    "\n",
    "def try_decode(nmea,bbox):\n",
    "    #bbox=[lllat,lllon,urlat,urlon]\n",
    "    try:\n",
    "        x=decode_nmea_no_prefix(nmea)\n",
    "        lat=x['y']\n",
    "        lon=x['x']\n",
    "        \n",
    "        if lat > bbox[0] and lat < bbox[2] and lon > bbox[1] and lon < bbox[3]:\n",
    "            decoded_list=[int(x['mmsi']),x['unixtime'],float(x['x']),float(x['y']),x['geohash'],float(x['sog']),float(x['rot']),float(x['cog'])]\n",
    "        else:\n",
    "            decoded_list=[]\n",
    "            \n",
    "    except:\n",
    "        decoded_list=[]\n",
    "\n",
    "    return decoded_list\n",
    "\n",
    "def decode_nmea_no_prefix(nmea):\n",
    "    commasplit=nmea.split(',')\n",
    "    \n",
    "    nmea_talkerid=commasplit[1].split('\\\\')[-1]\n",
    "    fragment_no=commasplit[3]\n",
    "    seq_message_id=commasplit[4]\n",
    "    payload=commasplit[-2]\n",
    "    fill_bits=int(commasplit[-1][0])\n",
    "\n",
    "    #Decode ais payload\n",
    "    msg_type=[]\n",
    "    try:\n",
    "        aisdata=ais.decode(payload,fill_bits)\n",
    "        msg_type=int(aisdata['id'])\n",
    "    except:\n",
    "        try:\n",
    "            fill_bits=2\n",
    "            aisdata=ais.decode(payload,fill_bits)\n",
    "            msg_type=int(aisdata['id'])\n",
    "        except:\n",
    "            msg_type=30\n",
    "            aisdata={'id':msg_type}\n",
    "    if msg_type==20:\n",
    "        aisdata=unroll_msg20(aisdata)\n",
    "\n",
    "    if 'x' in aisdata and 'y' in aisdata: # and 'x'!=181 and 'y'!=91: # x- longitude , y- latitude\n",
    "        try:\n",
    "            aisdata[u'geohash'] = geohash.encode(aisdata['y'],aisdata['x'],13)\n",
    "        except:\n",
    "            aisdata[u'geohash'] = '0'\n",
    "\n",
    "\n",
    "    #Append NMEA Tag Blocks         \n",
    "    aisdata[u'unixtime'] = int(time.time()) # since no timestamp is included, set it to utc.now\n",
    "    aisdata[u'n_talkerid'] = nmea_talkerid\n",
    "    aisdata[u'n_fragmentno'] = fragment_no\n",
    "    aisdata[u'n_seqmsg'] = seq_message_id\n",
    "    aisdata[u'n_aispayload'] = payload\n",
    "    aisdata[u'n_fillbits'] = fill_bits\n",
    "   \n",
    "    return aisdata"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialisation Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
