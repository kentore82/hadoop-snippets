{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Spark and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T10:36:56.897908",
     "start_time": "2016-11-21T10:36:56.890304"
    },
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Import Spark bindings\n",
    "execfile(\"/etc/spark/conf/spark_1.6.0_binings.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T10:36:58.975397",
     "start_time": "2016-11-21T10:36:56.900402"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ais\n",
    "import time\n",
    "import numpy as np\n",
    "import threading\n",
    "import Queue\n",
    "from datetime import datetime\n",
    "import happybase\n",
    "from Geohash import geohash\n",
    "from scipy.spatial import distance\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "#plotly\n",
    "import plotly\n",
    "import plotly.plotly as py  \n",
    "import plotly.tools as tls   \n",
    "import plotly.graph_objs as go\n",
    "import randomcolor\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T10:38:33.775987",
     "start_time": "2016-11-21T10:38:20.764576"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set distribution mode, appname, and claim resources\n",
    "master='yarn-client' #\"yarn\" to run distributed mode in yarn, \"local\" to run local\n",
    "#dmode='client' #spark2.0 only\n",
    "AppName=\"AIS - streaming Kystverket\"\n",
    "num_executors=2\n",
    "exec_memory=1 #in GigaByte pr. executor. Tot mem = num_executors*exec_memory\n",
    "driver_memory=1 #in GigaByte.\n",
    "\n",
    "\n",
    "\n",
    "#############--==DO NOT EDIT==--###############\n",
    "from pyspark import SparkConf\n",
    "sconf=SparkConf()\n",
    "\n",
    "sconf.set('spark.master',master)\n",
    "#sconf.set('spark.submit.deployMode',dmode) #spark2.0 only\n",
    "sconf.set('spark.executor.instances',str(num_executors))#Number of executors\n",
    "#sconf.set('spark.shuffle.service.enabled',True)\n",
    "#sconf.set('spark.dynamicAllocation.enabled',True)\n",
    "sconf.set('spark.executor.memory',str(exec_memory)+'g')\n",
    "sconf.set('spark.driver.memory',str(driver_memory)+'g')\n",
    "#sconf.set('spark.executor.cores','2') # number of cores on same worker\n",
    "sconf.set('spark.app.name',AppName) #Application Name\n",
    "sconf.set('spark.app.id',AppName)\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "sc = SparkContext(conf=sconf)\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-11T14:42:20.313083",
     "start_time": "2016-11-11T14:42:15.938511"
    },
    "collapsed": false
   },
   "source": [
    "## Streaming Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-22T12:20:59.536025",
     "start_time": "2016-11-22T12:20:59.427942"
    },
    "cell_style": "split",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#STREAM DATA\n",
    "threads = []\n",
    "q = Queue.Queue()\n",
    "\n",
    "if 't_list' in locals() or 'ssc' in locals():\n",
    "    del t_list\n",
    "    del ssc\n",
    "batch_interval=1#Seconds\n",
    "ssc = StreamingContext(sc, batch_interval)\n",
    "\n",
    "#Kystverket's open streaming connection:\n",
    "streaming_host = \"153.44.253.27\"\n",
    "streaming_port = 5631\n",
    "\n",
    "#Set region of interest\n",
    "#bbox=[lllat,lllon,urlat,urlon]\n",
    "#bbox=[59.0, 10.224365,59.881444, 11.728791]# <- Oslofjorden \n",
    "bbox=[0,0,100,100]\n",
    "\n",
    "#Dump data or not\n",
    "dump_data=False\n",
    "\n",
    "threads.append(threading.Thread(target=spark_stream,\\\n",
    "                            args=(sc, ssc,streaming_host,streaming_port,q,bbox,dump_data)))\n",
    "\n",
    "t_list=[t.start() for t in threads]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T10:36:59.004555",
     "start_time": "2016-11-21T10:36:58.977720"
    },
    "cell_style": "split",
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def spark_stream(sc, ssc,streaming_host,streaming_port,q,bbox,dump_data):\n",
    "    #Connect to stream\n",
    "    nmea = ssc.socketTextStream(streaming_host, streaming_port)\n",
    "\n",
    "    # Decode and filter bad messages\n",
    "    nmea_decoded = nmea.map(lambda x: try_decode(x,bbox))\n",
    "    nmea_decoded = nmea_decoded.filter(lambda x:x!=[])\n",
    "\n",
    "    # Connect to HBase and add metadata about vessel\n",
    "    nmea_decoded = nmea_decoded.map(lambda x: x+[get_meta_from_mmsi(str(x[0]))[\"P:imo\"],\\\n",
    "                                                 get_meta_from_mmsi(str(x[0]))[\"P:name\"],\\\n",
    "                                                 get_meta_from_mmsi(str(x[0]))[\"P:type\"]])\n",
    "\n",
    "    nmea_decoded = nmea_decoded.filter(lambda x:x[9]!='not_found')\n",
    "    \n",
    "    # Split stream \n",
    "    nmea_decoded_to_plot=nmea_decoded\n",
    "    \n",
    "    #since rdd is small collect and save to local FS\n",
    "    if dump_data==True:\n",
    "        nmea_decoded_to_plot.foreachRDD(lambda rdd: q.put(rdd.collect()))\n",
    "        nmea_decoded.map(lambda x: rdd_list_to_str(x))\\\n",
    "        .foreachRDD(lambda rdd: save_to_local(rdd.collect()))\n",
    "    else:\n",
    "        # Collect and put in que\n",
    "        nmea_decoded.foreachRDD(lambda rdd: q.put(rdd.collect()))\n",
    "\n",
    "    # Run!\n",
    "    ssc.start()\n",
    "    ssc.awaitTermination(timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-22T12:21:54.237811",
     "start_time": "2016-11-22T12:21:53.896440"
    },
    "cell_style": "split",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stop StreamingContext\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-22T12:28:06.489577",
     "start_time": "2016-11-22T12:28:06.020307"
    },
    "cell_style": "split",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stop SparkContext\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-11T14:27:17.909627",
     "start_time": "2016-11-11T14:27:17.810672"
    }
   },
   "source": [
    "## Find vessels to follow on map: follow on your laptop now - https://plot.ly/~kentt/181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-17T09:09:26.158969",
     "start_time": "2016-11-17T09:08:29.480899"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxpoints=10\n",
    "num_ship=25\n",
    "mmsi_dict=follow_mmsi(q,maxpoints,num_ship)\n",
    "init_streaming_plot('AISstream',mmsi_dict)\n",
    "\n",
    "iframe = '<iframe width=\"1000\" height=\"800\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~kentt/181.embed\"></iframe>'\n",
    "IPython.display.HTML(iframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-11T14:55:17.749888",
     "start_time": "2016-11-11T14:55:16.211165"
    },
    "collapsed": true
   },
   "source": [
    "## Start stream to map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-11-17T08:11:21.657Z"
    },
    "cell_style": "center",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    #init stream data to plot\n",
    "    #Init streaming\n",
    "    ship_info_dict,plotly_stream_dict=plotly_stream_init(mmsi_dict)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ship_info_dict_new=acc_points(ship_info_dict.copy(),q.get(),maxpoints)\n",
    "\n",
    "        #Get updated keys\n",
    "        for key in mmsi_dict.keys():\n",
    "            if ship_info_dict_new[key]==ship_info_dict[key]:\n",
    "                pass\n",
    "            else:\n",
    "                ship_info_dict[key]=ship_info_dict_new[key]\n",
    "                lets_stream({key:ship_info_dict[key]},{key:plotly_stream_dict[key]},{key:mmsi_dict[key]}) #test_stream,s)#\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    plotly_stream_close(plotly_stream_dict)\n",
    "    print('Aborting on Ctrl-C, goodbye!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T10:36:59.744215",
     "start_time": "2016-11-21T10:36:59.006516"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#INIT STREAMING PLOT\n",
    "def init_streaming_plot(figname,mmsi_dict):\n",
    "    # init mapboxplot, data and layout\n",
    "    mapbox_access_token = \"pk.eyJ1Ijoia2VudHQiLCJhIjoiY2l1dHIyMmsyMDAwZTJ5czlwNTY4c3E2ZCJ9.IcUEo9TXPyTiwMmrEiikvQ\"\n",
    "\n",
    "    data = []\n",
    "    for key in mmsi_dict.keys():\n",
    "        data_init=dict(\n",
    "            type='scattermapbox',\n",
    "            lon=[],\n",
    "            lat=[],\n",
    "            mode='markers',\n",
    "            marker={'size':10,'color':mmsi_dict[key]['color']},\n",
    "            stream=mmsi_dict[key]['stream_id'],\n",
    "            name=mmsi_dict[key][\"name\"])\n",
    "\n",
    "        data.append(data_init)\n",
    "\n",
    "    layout = go.Layout(\n",
    "        autosize=True,\n",
    "        hovermode='closest',\n",
    "        mapbox=dict(\n",
    "            accesstoken=mapbox_access_token,\n",
    "            bearing=0,\n",
    "            center=dict(\n",
    "                lon=10,\n",
    "                lat=59\n",
    "            ),\n",
    "            pitch=60,\n",
    "            zoom=7\n",
    "        ),\n",
    "        width  = '1000',\n",
    "        height = '800',\n",
    "    )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    py.iplot(fig, filename=figname)\n",
    "\n",
    "def plotly_stream_init(mmsi_dict):\n",
    "    ship_info_dict={}\n",
    "    plotly_stream_dict={}\n",
    "    \n",
    "    for key in mmsi_dict.keys():\n",
    "        #Init empty data dict\n",
    "        ship_info_dict[key]=[[],[],[],[],[],[],[],[],[],[],[]]\n",
    "        #Init streaming objects\n",
    "        plotly_stream_dict[key]=py.Stream(stream_id=mmsi_dict[key][\"token\"])\n",
    "        plotly_stream_dict[key].open()\n",
    "\n",
    "    return ship_info_dict,plotly_stream_dict\n",
    "\n",
    "def plotly_stream_close(plotly_stream_dict):\n",
    "    for key in plotly_stream_dict.keys():\n",
    "        plotly_stream_dict[key].close()\n",
    "\n",
    "\n",
    "#Get list of mmsi's to follow\n",
    "def follow_mmsi(q,mpoints,num_ship):\n",
    "    #Accumulate q.get() to get a good base to pick mmsi's\n",
    "    q_acc=[]\n",
    "    \n",
    "    stream_tokens = tls.get_credentials_file()['stream_ids']\n",
    "    mmsi_stream_token={}\n",
    "    \n",
    "    while len(mmsi_stream_token.keys())<num_ship:\n",
    "        mmsi_list=[]\n",
    "        q_acc.append(q.get())\n",
    "        time.sleep(0.3)\n",
    "        \n",
    "        for item in q_acc:\n",
    "            for sub_item in item:\n",
    "                mmsi_list.append(sub_item[0])\n",
    "\n",
    "        mmsi_list = list(sorted(set(mmsi_list)))\n",
    "\n",
    "        #Check HBase if ship name is found:\n",
    "        for i in range(0,len(mmsi_list)):\n",
    "            mmsi=mmsi_list[i]\n",
    "\n",
    "            info_dict=get_meta_from_mmsi(str(mmsi))\n",
    "            mmsi_list[i]=(mmsi,info_dict['P:name'])\n",
    "\n",
    "        if len(mmsi_list)>len(stream_tokens):\n",
    "            N=len(stream_tokens)\n",
    "        else:\n",
    "            N=len(mmsi_list)\n",
    "\n",
    "        for i in range(0,N):\n",
    "            token=stream_tokens[i]\n",
    "            mmsi=mmsi_list[i][0]\n",
    "            name=mmsi_list[i][1]\n",
    "\n",
    "            if name=='not_found':\n",
    "                continue\n",
    "            else:\n",
    "                mmsi_stream_token[mmsi]={\"token\":token,\"name\":name,\"mmsi\":mmsi,\"stream_id\":dict(token=token, maxpoints=mpoints),\"color\":randomcolor.RandomColor().generate()[0]}\n",
    "\n",
    "    return mmsi_stream_token\n",
    "\n",
    "def acc_points(ship_info_dict,q,maxpoints):\n",
    "    for row in q:\n",
    "        try:\n",
    "            ship_info=ship_info_dict[row[0]][:]\n",
    "            for i in range(0,len(ship_info)):\n",
    "                ship_info[i]=ship_info[i]+[row[i]]\n",
    "\n",
    "            ship_info_dict[row[0]]=ship_info\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #Limit the number of accumulated points\n",
    "    for key in ship_info_dict.keys():\n",
    "        if len(ship_info_dict[key][0])>maxpoints:\n",
    "            for i in range(0,len(ship_info_dict[key])):\n",
    "                ship_info_dict[key][i]=ship_info_dict[key][i][-maxpoints:]\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    return ship_info_dict\n",
    "\n",
    "def lets_stream(ship_info_dict,plotly_stream_dict,mmsi_dict):\n",
    "    \n",
    "    for key in mmsi_dict.keys():\n",
    "        if ship_info_dict[key][0]==[]:\n",
    "            continue\n",
    "        \n",
    "        ais=ship_info_dict[key][:]\n",
    "        \n",
    "        col=mmsi_dict[key][\"color\"]\n",
    "        \n",
    "        imo = ais[8]\n",
    "        name = ais[9]\n",
    "        stype = ais[10]\n",
    "        SOG = ais[5]\n",
    "        COG = ais[7]\n",
    "        dtime = ais[1]\n",
    "        x_lon = ais[2]\n",
    "        y_lat = ais[3] \n",
    "        \n",
    "        plotly_stream_dict[key].write(go.Scattermapbox(lon=x_lon,\n",
    "                        lat=y_lat,\n",
    "                        marker=go.Marker(color=[col for i in range(0,len(imo)-1)]+[\"black\"]),\n",
    "                        text=['IMO: '+str(imo[i])+'<br>'\\\n",
    "                              +'Type: '+str(stype[i])+'<br>'\\\n",
    "                              +'Time: '+datetime.fromtimestamp(int(dtime[i])).strftime('%Y-%m-%d %H:%M:%S')+'<br>'\\\n",
    "                              +'COG: '+str(int(COG[i]))+' deg'+'<br>'\\\n",
    "                              +'SOG: '+str(int(SOG[i]))+' kn' for i in range(0,len(imo))]))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def identify_nearest_neighbour(rdd):\n",
    "    try:\n",
    "        rdd_nn=[]\n",
    "        for line in rdd:\n",
    "            mmsi=line[0]\n",
    "            pos_mmsi=(line[2],line[3])\n",
    "\n",
    "            #Make list of all neighbours positions\n",
    "            pos_neighbours=[]\n",
    "            pos_names=[]\n",
    "            for row in rdd:\n",
    "                pos_neighbour=[row[2],row[3]]\n",
    "                pos_name=row[9]\n",
    "                if [pos_mmsi[0],pos_mmsi[1]] != pos_neighbour:\n",
    "                    pos_neighbours.append(pos_neighbour)\n",
    "                    pos_names.append(pos_name)\n",
    "\n",
    "            #Find closest point:\n",
    "            pos_neighbours=np.array(pos_neighbours)\n",
    "            mmsi_nn_point=pos_neighbours[distance.cdist([pos_mmsi], pos_neighbours).argmin()]\n",
    "            mmsi_nn_distance=vincenty(pos_mmsi,(mmsi_nn_point[0],mmsi_nn_point[1])).kilometers\n",
    "\n",
    "            #Find ID of closest point:\n",
    "            mmsi_nn_name=pos_names[pos_neighbours.tolist().index(mmsi_nn_point.tolist())]\n",
    "\n",
    "            #Append to RDD\n",
    "            rdd_nn.append(line+[mmsi_nn_name,mmsi_nn_distance])\n",
    "\n",
    "        return rdd_nn\n",
    "    except:\n",
    "        return rdd\n",
    "\n",
    "def save_to_local(rdd_collected):\n",
    "    filen='ais_'+str(int(time.time()))\n",
    "    dirpath=\"/STAGING/DATASETS/AIS/\"\n",
    "    dir_name='KV_ais_dump_'+datetime.fromtimestamp(time.time()).strftime('%Y%m%d')\n",
    "    if not os.path.exists(dirpath+dir_name):\n",
    "        os.makedirs(dirpath+dir_name)\n",
    "        os.system(\"chmod 777 \"+dirpath+dir_name)\n",
    "    \n",
    "    with open(dirpath+dir_name+'/'+filen, 'w') as file_handler:\n",
    "        for item in rdd_collected:\n",
    "            file_handler.write(item+'\\n')\n",
    "    os.system(\"chmod 777 \"+dirpath+dir_name+'/'+filen)\n",
    "    \n",
    "\n",
    "def rdd_list_to_str(rdd_list): \n",
    "    rdd_str=''\n",
    "    for el in rdd_list:\n",
    "        rdd_str=rdd_str+','+str(el)\n",
    "    \n",
    "    return rdd_str[1:]\n",
    "\n",
    "def get_meta_from_mmsi(mmsi):\n",
    "    #Create connection\n",
    "    connection = happybase.Connection('2.sherpa.client.sysedata.no')\n",
    "    connection.open()\n",
    "\n",
    "    table_name=\"mmsiShipInfo\"\n",
    "    table = connection.table(table_name)\n",
    "    info_dict=table.row(mmsi)\n",
    "    if info_dict=={}:\n",
    "        info_dict={'P:imo': 'not_found','P:mmsi': mmsi,'P:name': 'not_found','P:type': 'not_found'}\n",
    "    \n",
    "    connection.close()\n",
    "    return info_dict\n",
    "\n",
    "def try_decode(nmea,bbox):\n",
    "    #bbox=[lllat,lllon,urlat,urlon]\n",
    "    try:\n",
    "        x=decode_nmea_no_prefix(nmea)\n",
    "        lat=x['y']\n",
    "        lon=x['x']\n",
    "        \n",
    "        if lat > bbox[0] and lat < bbox[2] and lon > bbox[1] and lon < bbox[3]:\n",
    "            decoded_list=[int(x['mmsi']),x['unixtime'],float(x['x']),float(x['y']),x['geohash'],float(x['sog']),float(x['rot']),float(x['cog'])]\n",
    "        else:\n",
    "            decoded_list=[]\n",
    "            \n",
    "    except:\n",
    "        decoded_list=[]\n",
    "\n",
    "    return decoded_list\n",
    "\n",
    "def decode_nmea_no_prefix(nmea):\n",
    "    commasplit=nmea.split(',')\n",
    "    \n",
    "    nmea_talkerid=commasplit[1].split('\\\\')[-1]\n",
    "    fragment_no=commasplit[3]\n",
    "    seq_message_id=commasplit[4]\n",
    "    payload=commasplit[-2]\n",
    "    fill_bits=int(commasplit[-1][0])\n",
    "\n",
    "    #Decode ais payload\n",
    "    msg_type=[]\n",
    "    try:\n",
    "        aisdata=ais.decode(payload,fill_bits)\n",
    "        msg_type=int(aisdata['id'])\n",
    "    except:\n",
    "        try:\n",
    "            fill_bits=2\n",
    "            aisdata=ais.decode(payload,fill_bits)\n",
    "            msg_type=int(aisdata['id'])\n",
    "        except:\n",
    "            msg_type=30\n",
    "            aisdata={'id':msg_type}\n",
    "    if msg_type==20:\n",
    "        aisdata=unroll_msg20(aisdata)\n",
    "\n",
    "    if 'x' in aisdata and 'y' in aisdata: # and 'x'!=181 and 'y'!=91: # x- longitude , y- latitude\n",
    "        try:\n",
    "            aisdata[u'geohash'] = geohash.encode(aisdata['y'],aisdata['x'],13)\n",
    "        except:\n",
    "            aisdata[u'geohash'] = '0'\n",
    "\n",
    "\n",
    "    #Append NMEA Tag Blocks         \n",
    "    aisdata[u'unixtime'] = int(time.time()) # since no timestamp is included, set it to utc.now\n",
    "    aisdata[u'n_talkerid'] = nmea_talkerid\n",
    "    aisdata[u'n_fragmentno'] = fragment_no\n",
    "    aisdata[u'n_seqmsg'] = seq_message_id\n",
    "    aisdata[u'n_aispayload'] = payload\n",
    "    aisdata[u'n_fillbits'] = fill_bits\n",
    "   \n",
    "    return aisdata"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialisation Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
